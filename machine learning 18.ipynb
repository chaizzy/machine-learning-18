{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29cb8e75-f03a-4ea9-83c3-9d6b99bbd51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANS 1:\n",
    "# Ensemble technique in machine learning is combining of different models\n",
    "# An ensemble technique in machine learning refers to the combination of multiple individual models, \n",
    "# known as base models or weak learners, to create a more powerful and accurate model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a060cdb2-cf9d-424d-a86d-6468214c517c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANS 2 :\n",
    "# 1.Improved Accuracy: Ensemble methods have the potential to improve the overall accuracy of predictions compared to individual models.\n",
    "# 2.Reduced Overfitting: Ensemble techniques can help mitigate the risk of overfitting, \n",
    "#   which occurs when a model performs well on the training data but fails to generalize to new, unseen data.\n",
    "# 3.Handling Complexity: Ensemble methods can effectively handle complex relationships and capture nonlinearities in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb75b721-5175-40a3-8d5c-ad3efcccf92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANS 3 :\n",
    "# Bagging\n",
    "# Bagging, short for bootstrap aggregating, is a machine learning ensemble technique that \n",
    "# combines multiple individual models to make more accurate predictions. \n",
    "# It involves creating multiple subsets of the training dataset through a process called bootstrapping Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baa37634-dcbe-4324-b175-4995005eb1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANS 4:\n",
    "# Boosting\n",
    "# Boosting is another ensemble learning technique that combines multiple weak models to create a strong predictive model.\n",
    "# Unlike bagging, boosting focuses on sequentially building a series of models, \n",
    "# where each subsequent model tries to correct the mistakes made by the previous ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855f7728-ba09-430c-876a-49692ebd3f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANS 5:\n",
    "# 1.Improved Accuracy: Ensemble methods have the potential to improve the overall accuracy of predictions compared to individual models.\n",
    "# 2.Reduced Overfitting: Ensemble techniques can help mitigate the risk of overfitting, \n",
    "#   which occurs when a model performs well on the training data but fails to generalize to new, unseen data.\n",
    "# 3.Handling Complexity: Ensemble methods can effectively handle complex relationships and capture nonlinearities in the data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53678535-7361-4f45-8cf4-c69355c8f9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANS 6 :\n",
    "# Ensemble techniques are particularly beneficial when the individual models have diverse strengths and weaknesses. By combining different models \n",
    "# the ensemble can leverage their collective knowledge and compensate for individual model limitations, leading to better overall performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ba9ef45-42b7-458c-ba56-0289fd9a5236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANS 7 :\n",
    "# 1.Collect the original dataset of size N.\n",
    "# 2.Generate B bootstrap samples by randomly sampling N instances from the original dataset with replacement. \n",
    "#  Each bootstrap sample will have N instances, and some instances may appear multiple times while others may not appear at all.\n",
    "# 3.Compute the statistic of interest (e.g., mean, median, standard deviation, etc.) on each bootstrap sample. \n",
    "#   This will result in B bootstrap statistics.\n",
    "# 4.Sort the B bootstrap statistics in ascending order.\n",
    "# 5.Determine the lower and upper percentiles of interest. For example, if you want to calculate a 95% confidence interval, you would typically choose the 2.5th and 97.5th percentiles.\n",
    "# 6.The lower percentile will represent the lower bound of the confidence interval, and the upper percentile will represent the upper bound.\n",
    "# 7.The resulting range between the lower and upper bounds is the bootstrap confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd059f2c-d96d-445b-9095-39f8cb8d07de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANS 8:\n",
    "# 1.Obtain the original dataset: Start with a dataset of size N, which represents the population or the available sample.\n",
    "# 2.Resample with replacement: Randomly select N instances from the original dataset, allowing instances to be chosen multiple times (with replacement). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ed9cc4d-11b5-4e7d-b6a4-4817b84221b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d08cf828-1ad1-477c-a554-3a40328d08bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence Interval: [15.00, 15.00]\n"
     ]
    }
   ],
   "source": [
    "# ANS 9:\n",
    "import numpy as np\n",
    "\n",
    "sample_heights = np.array([15] * 50)  \n",
    "def bootstrap_sample(data):\n",
    "    n = len(data)\n",
    "    indices = np.random.randint(0, n, size=n)\n",
    "    return data[indices]\n",
    "\n",
    "B = 10000  \n",
    "bootstrap_means = np.zeros(B)\n",
    "for i in range(B):\n",
    "    bootstrap_sample_data = bootstrap_sample(sample_heights)\n",
    "    bootstrap_means[i] = np.mean(bootstrap_sample_data)\n",
    "\n",
    "lower_percentile = np.percentile(bootstrap_means, 2.5)\n",
    "upper_percentile = np.percentile(bootstrap_means, 97.5)\n",
    "\n",
    "print(\"95% Confidence Interval: [{:.2f}, {:.2f}]\".format(lower_percentile, upper_percentile))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87f93a7-c67d-4fad-a656-8e9a9b956505",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
